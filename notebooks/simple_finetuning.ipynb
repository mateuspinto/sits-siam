{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "\n",
    "from print_color import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TRANSFORMER_FROM_SCRATCH\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sits_siam.backbone import TransformerBackbone\n",
    "from sits_siam.head import BertHead, ClassifierHead\n",
    "from sits_siam.utils import SitsDataset\n",
    "from sits_siam.bottleneck import PoolingBottleneck, NDVIWord2VecBottleneck\n",
    "from sits_siam.augment import AddNDVIWeights, RandomChanSwapping, RandomChanRemoval, RandomAddNoise, RandomTempSwapping, RandomTempShift, RandomTempRemoval, AddMissingMask, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed():\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# setup_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_parquet(\"data/california_sits_bert_original.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = [0.0656, 0.0948, 0.1094, 0.1507, 0.2372, 0.2673, 0.2866, 0.2946, 0.2679, 0.1985]\n",
    "iqd = [0.0456, 0.0536, 0.0946, 0.0769, 0.0851, 0.1053, 0.1066, 0.1074, 0.1428, 0.1376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = [\n",
    "    AddNDVIWeights(),\n",
    "    RandomAddNoise(),\n",
    "    RandomTempSwapping(),\n",
    "    RandomTempShift(),\n",
    "    # RandomTempRemoval(),\n",
    "    AddMissingMask(),\n",
    "    Normalize(\n",
    "        a=[\n",
    "            0.0656,\n",
    "            0.0948,\n",
    "            0.1094,\n",
    "            0.1507,\n",
    "            0.2372,\n",
    "            0.2673,\n",
    "            0.2866,\n",
    "            0.2946,\n",
    "            0.2679,\n",
    "            0.1985,\n",
    "        ],\n",
    "        b=[\n",
    "            0.0456,\n",
    "            0.0536,\n",
    "            0.0946,\n",
    "            0.0769,\n",
    "            0.0851,\n",
    "            0.1053,\n",
    "            0.1066,\n",
    "            0.1074,\n",
    "            0.1428,\n",
    "            0.1376,\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "val_transforms = [\n",
    "    AddNDVIWeights(),\n",
    "    AddMissingMask(),\n",
    "    Normalize(\n",
    "        a=[\n",
    "            0.0656,\n",
    "            0.0948,\n",
    "            0.1094,\n",
    "            0.1507,\n",
    "            0.2372,\n",
    "            0.2673,\n",
    "            0.2866,\n",
    "            0.2946,\n",
    "            0.2679,\n",
    "            0.1985,\n",
    "        ],\n",
    "        b=[\n",
    "            0.0456,\n",
    "            0.0536,\n",
    "            0.0946,\n",
    "            0.0769,\n",
    "            0.0851,\n",
    "            0.1053,\n",
    "            0.1066,\n",
    "            0.1074,\n",
    "            0.1428,\n",
    "            0.1376,\n",
    "        ],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split whole df by unique ids\n",
    "ids = whole_df.id.unique()\n",
    "np.random.shuffle(ids)\n",
    "train_ids = ids[:int(len(ids) * 0.8)]\n",
    "val_ids = ids[int(len(ids) * 0.8):]\n",
    "\n",
    "train_df = whole_df[whole_df.id.isin(train_ids)].reset_index(drop=True)\n",
    "val_df = whole_df[whole_df.id.isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = SitsDataset(train_df, max_seq_len=45, transform=train_transforms)\n",
    "val_dataset = SitsDataset(val_df, max_seq_len=45, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(pl.LightningModule):\n",
    "    def __init__(self, max_seq_len=40, num_classes=13):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.backbone = TransformerBackbone(max_seq_len=max_seq_len)\n",
    "        self.bottleneck = NDVIWord2VecBottleneck()\n",
    "        self.classifier = ClassifierHead(num_classes=num_classes)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.val_f1 = MulticlassF1Score(num_classes=num_classes, average='macro')\n",
    "        self.test_f1 = MulticlassF1Score(num_classes=num_classes, average='macro')\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input[\"x\"]\n",
    "        doy = input[\"doy\"]\n",
    "        mask = input[\"mask\"]\n",
    "        weight = input[\"weight\"]\n",
    "\n",
    "        features = self.backbone(x, doy, mask)\n",
    "        features = self.bottleneck(features, weight)\n",
    "        outputs = self.classifier(features)\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        targets = batch[\"y\"]\n",
    "        outputs = self(batch)\n",
    "\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        # Log loss and F1 score\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        targets = batch[\"y\"]\n",
    "        outputs = self(batch)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        f1_score = self.val_f1(preds, targets)\n",
    "\n",
    "        # Log loss and F1 score\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_score, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        targets = batch[\"y\"]\n",
    "        outputs = self(batch)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        f1_score = self.test_f1(preds, targets)\n",
    "\n",
    "        # Log loss and F1 score\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_f1\", f1_score)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=1e-2)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=10)\n",
    "model = TransformerClassifier()\n",
    "\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
