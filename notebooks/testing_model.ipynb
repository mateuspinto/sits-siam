{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW, Adam\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "import copy\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False, profile=\"full\", threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_function(name):\n",
    "    if name == \"relu\":\n",
    "        return F.relu\n",
    "    elif name == \"gelu\":\n",
    "        return F.gelu\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation function: {name}\")\n",
    "\n",
    "\n",
    "def get_activation_module(name):\n",
    "    if name == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    elif name == \"gelu\":\n",
    "        return nn.GELU()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation function: {name}\")\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Compute 'Scaled Dot Product Attention' without using the math library.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)\n",
    "        # Compute scaled dot-product attention\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(\n",
    "            torch.tensor(d_k, dtype=query.dtype, device=query.device)\n",
    "        )\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float(\"-inf\"))\n",
    "\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "\n",
    "        output = torch.matmul(p_attn, value)\n",
    "        return output, p_attn\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Headed Attention module without using built-in attention modules.\n",
    "    Supports parameters: d_model, num_heads, dropout, batch_first.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1, batch_first=True):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.linear_layers = nn.ModuleList(\n",
    "            [nn.Linear(d_model, d_model) for _ in range(3)]\n",
    "        )\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "        self.attention = Attention()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_len, _ = query.size()\n",
    "        else:\n",
    "            seq_len, batch_size, _ = query.size()\n",
    "            # Transpose to batch first\n",
    "            query = query.transpose(0, 1)\n",
    "            key = key.transpose(0, 1)\n",
    "            value = value.transpose(0, 1)\n",
    "\n",
    "        # Linear projections\n",
    "        query, key, value = [\n",
    "            linear(x)\n",
    "            .view(batch_size, seq_len, self.num_heads, self.d_k)\n",
    "            .transpose(1, 2)\n",
    "            for linear, x in zip(self.linear_layers, (query, key, value))\n",
    "        ]  # Each tensor is of shape (batch_size, num_heads, seq_len, d_k)\n",
    "\n",
    "        # Prepare masks\n",
    "        if key_padding_mask is not None:\n",
    "            # key_padding_mask: (batch_size, seq_len)\n",
    "            # Expand to (batch_size, 1, 1, seq_len)\n",
    "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(\n",
    "                2\n",
    "            )  # (batch_size, 1, 1, seq_len)\n",
    "            # Expand to match the number of heads\n",
    "            key_padding_mask = key_padding_mask.expand(-1, self.num_heads, -1, -1)\n",
    "        if attn_mask is not None:\n",
    "            # attn_mask: (seq_len, seq_len)\n",
    "            attn_mask = attn_mask.unsqueeze(0)  # (1, seq_len, seq_len)\n",
    "            attn_mask = attn_mask.expand(batch_size * self.num_heads, -1, -1).view(\n",
    "                batch_size, self.num_heads, seq_len, seq_len\n",
    "            )\n",
    "        # Combine masks\n",
    "        if key_padding_mask is not None and attn_mask is not None:\n",
    "            combined_mask = key_padding_mask | attn_mask\n",
    "        elif key_padding_mask is not None:\n",
    "            combined_mask = key_padding_mask\n",
    "        elif attn_mask is not None:\n",
    "            combined_mask = attn_mask\n",
    "        else:\n",
    "            combined_mask = None\n",
    "\n",
    "        # Apply attention\n",
    "        x, attn = self.attention(\n",
    "            query, key, value, mask=combined_mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # Concatenate heads and apply final linear layer\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
    "        x = self.output_linear(x)\n",
    "\n",
    "        if not self.batch_first:\n",
    "            x = x.transpose(0, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        batch_first=True,\n",
    "    ):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadedAttention(\n",
    "            d_model, num_heads, dropout=dropout, batch_first=batch_first\n",
    "        )\n",
    "        # Feedforward network\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.activation_fn = get_activation_function(activation)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # Self-attention\n",
    "        attn_output = self.self_attn(\n",
    "            src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "        src = src + self.dropout1(attn_output)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        # Feedforward network\n",
    "        ff_output = self.linear2(self.dropout(self.activation_fn(self.linear1(src))))\n",
    "        src = src + self.dropout2(ff_output)\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [copy.deepcopy(encoder_layer) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        output = src\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = layer(\n",
    "                output, src_mask=mask, src_key_padding_mask=src_key_padding_mask\n",
    "            )\n",
    "\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SitsTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=10,\n",
    "        num_classes=13,\n",
    "        d_model=128,\n",
    "        n_head=16,\n",
    "        n_layers=1,\n",
    "        d_inner=128,\n",
    "        activation=\"relu\",\n",
    "        dropout=0.2,\n",
    "        max_len=366,\n",
    "        max_seq_len=70,\n",
    "        T=1000,\n",
    "        max_temporal_shift=30,\n",
    "    ):\n",
    "        super(SitsTransformer, self).__init__()\n",
    "        self.modelname = self._get_name()\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self.mlp_dim = [input_dim, 32, 64, d_model]\n",
    "        layers = []\n",
    "        for i in range(len(self.mlp_dim) - 1):\n",
    "            layers.append(LinLayer(self.mlp_dim[i], self.mlp_dim[i + 1]))\n",
    "        self.mlp1 = nn.Sequential(*layers)\n",
    "\n",
    "        self.inlayernorm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.position_enc = PositionalEncoding(\n",
    "            d_model, max_len=max_len + 2 * max_temporal_shift, T=T\n",
    "        )\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model, n_head, d_inner, dropout, activation, batch_first=True\n",
    "        )\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.transformerencoder = TransformerEncoder(\n",
    "            encoder_layer, n_layers, encoder_norm\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        decoder = [d_model, 64, 32, num_classes]\n",
    "        for i in range(len(decoder) - 1):\n",
    "            layers.append(nn.Linear(decoder[i], decoder[i + 1]))\n",
    "            if i < (len(decoder) - 2):\n",
    "                layers.extend([nn.BatchNorm1d(decoder[i + 1]), nn.ReLU()])\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "        self.input_sample = {\n",
    "            \"doy\": torch.randint(1, max_len, (2, self.max_seq_len), dtype=torch.int64),\n",
    "            \"mask\": torch.zeros((2, self.max_seq_len), dtype=torch.bool),\n",
    "            \"weight\": torch.rand((2, self.max_seq_len), dtype=torch.float32),\n",
    "            \"x\": torch.rand((2, self.max_seq_len, input_dim), dtype=torch.float32)\n",
    "        }\n",
    "        self.expected_output_sample = torch.rand((2, num_classes), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, input, is_bert=False):\n",
    "        x = input[\"x\"]\n",
    "        doy = input[\"doy\"]\n",
    "        mask = input[\"mask\"]\n",
    "        weight = input[\"weight\"]\n",
    "\n",
    "        x = self.mlp1(x)\n",
    "\n",
    "        x = self.inlayernorm(x)\n",
    "        x = self.dropout(x + self.position_enc(doy))\n",
    "\n",
    "        x = self.transformerencoder(x, src_key_padding_mask=mask)\n",
    "\n",
    "        if not is_bert:\n",
    "            weight = self.dropout(weight)\n",
    "            weight /= weight.sum(1, keepdim=True)\n",
    "            x = torch.bmm(weight.unsqueeze(1), x).squeeze()\n",
    "        else:\n",
    "            x, _ = torch.max(x, dim=1)\n",
    "\n",
    "        logits = self.decoder(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000, T: int = 10000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(T) / d_model))\n",
    "        pe = torch.zeros(max_len + 1, d_model)\n",
    "        pe[1:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[1:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, doy):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            doy: Tensor, shape [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        return self.pe[doy]\n",
    "\n",
    "\n",
    "class LinLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(LinLayer, self).__init__()\n",
    "        self.lin = nn.Linear(in_dim, out_dim)\n",
    "        self.ln = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.ln(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency of output sample\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model = SitsTransformer()\n",
    "    output = model(model.input_sample)\n",
    "    assert output.shape == model.expected_output_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(x):\n",
    "    all_zero_mask = np.all(x == 0, axis=1)\n",
    "\n",
    "    score = np.ones(x.shape[0])\n",
    "    score = np.minimum(score, (x[:, [0, 1, 2]].sum(1) - 0.2) / 0.6)  # rgb\n",
    "    cloud = score * 100 > 20\n",
    "    dark = x[:, [6, 8, 9]].sum(1) < 0.35 # NIR, SWIR1, SWIR2\n",
    "\n",
    "    ndvi = (x[:, 6] - x[:, 2]) / (x[:, 6] + x[:, 2] + 1e-8)\n",
    "    ndvi[cloud] = -1\n",
    "    ndvi[dark] = -1\n",
    "    ndvi = ndvi.clip(-1, 1)\n",
    "\n",
    "    weight = np.exp(ndvi)\n",
    "    weight /= weight.sum()\n",
    "\n",
    "    weight[all_zero_mask] = 0\n",
    "    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, mean, std):\n",
    "    x = x.copy()\n",
    "    \n",
    "    all_zero_mask = np.all(x == 0, axis=1)\n",
    "\n",
    "    x = (x - mean) / std\n",
    "    x[all_zero_mask] = 0\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SitsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, mean=None, std=None):\n",
    "        self.mean = np.array([[0.0656, 0.0948, 0.1094, 0.1507, 0.2372, 0.2673, 0.2866, 0.2946, 0.2679, 0.1985]], dtype=np.half)\n",
    "        self.std = np.array([0.036289, 0.043310, 0.064736, 0.057953, 0.074167, 0.096407, 0.097816, 0.098368, 0.089847, 0.097866], dtype=np.half)\n",
    "\n",
    "        self.xs = np.zeros((dataframe.id.nunique(), 70, 10), dtype=np.half)\n",
    "        self.doys = np.zeros((dataframe.id.nunique(), 70), np.int16)\n",
    "        self.ys = dataframe[[\"id\", \"label\"]].groupby(\"id\").first().label.to_numpy()\n",
    "\n",
    "        for _, row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "            self.xs[int(row.id - dataframe.id.min()), int(row.time)] = [row.blue, row.green, row.red, row.red_edge_1, row.red_edge_2, row.red_edge_3, row.nir, row.red_edge_4, row.swir_1, row.swir_2]\n",
    "            self.doys[int(row.id - dataframe.id.min()), int(row.time)] = row.doy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ys.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "\n",
    "        return {\n",
    "            \"doy\": torch.from_numpy(self.doys[idx]).long(),\n",
    "            \"mask\": torch.from_numpy(x.sum(1) == 0),\n",
    "            \"x\": torch.from_numpy(normalize(x, self.mean, self.std)).float(),\n",
    "            \"weight\": torch.from_numpy(get_weight(x)).float(),\n",
    "        }, torch.tensor(self.ys[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SitsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, mean=None, std=None):\n",
    "        self.mean = np.array([[0.0656, 0.0948, 0.1094, 0.1507, 0.2372,\n",
    "                               0.2673, 0.2866, 0.2946, 0.2679, 0.1985]],\n",
    "                             dtype=np.half)\n",
    "        self.std = np.array([0.036289, 0.043310, 0.064736, 0.057953, 0.074167,\n",
    "                             0.096407, 0.097816, 0.098368, 0.089847, 0.097866],\n",
    "                            dtype=np.half)\n",
    "\n",
    "        bands = ['blue', 'green', 'red', 'red_edge_1', 'red_edge_2',\n",
    "                 'red_edge_3', 'nir', 'red_edge_4', 'swir_1', 'swir_2']\n",
    "\n",
    "        # Sort the dataframe by 'id' and 'time'\n",
    "        dataframe = dataframe.sort_values(['id', 'time'])\n",
    "\n",
    "        # Extract numpy arrays from dataframe columns\n",
    "        ids = dataframe['id'].to_numpy()\n",
    "        times = dataframe['time'].astype(int).to_numpy()\n",
    "        doys = dataframe['doy'].to_numpy()\n",
    "        bands_data = dataframe[bands].to_numpy()\n",
    "\n",
    "        # Map unique ids to indices\n",
    "        unique_ids, id_indices = np.unique(ids, return_inverse=True)\n",
    "        num_ids = len(unique_ids)\n",
    "\n",
    "        # Initialize arrays\n",
    "        self.xs = np.zeros((num_ids, 70, 10), dtype=np.half)\n",
    "        self.doys = np.zeros((num_ids, 70), dtype=np.int16)\n",
    "\n",
    "        # Assign values using advanced indexing\n",
    "        self.xs[id_indices, times, :] = bands_data\n",
    "        self.doys[id_indices, times] = doys\n",
    "\n",
    "        # Extract labels\n",
    "        labels_df = dataframe[['id', 'label']].drop_duplicates('id').set_index('id')\n",
    "        self.ys = labels_df.loc[unique_ids, 'label'].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ys.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        return {\n",
    "            \"doy\": torch.from_numpy(self.doys[idx]).long(),\n",
    "            \"mask\": torch.from_numpy(x.sum(1) == 0),\n",
    "            \"x\": torch.from_numpy(normalize(x, self.mean, self.std)).float(),\n",
    "            \"weight\": torch.from_numpy(get_weight(x)).float(),\n",
    "        }, torch.tensor(self.ys[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_parquet(\"data/california_sits_bert_original.parquet\")\n",
    "train_df = whole_df[whole_df[\"use_bert\"] == 0].reset_index(drop=True)\n",
    "val_df = whole_df[whole_df[\"use_bert\"] == 1].reset_index(drop=True)\n",
    "\n",
    "train_dataset = SitsDataset(train_df)\n",
    "val_dataset = SitsDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split whole df by unique ids\n",
    "ids = whole_df.id.unique()\n",
    "np.random.shuffle(ids)\n",
    "train_ids = ids[:int(len(ids) * 0.8)]\n",
    "val_ids = ids[int(len(ids) * 0.8):]\n",
    "\n",
    "train_df = whole_df[whole_df.id.isin(train_ids)].reset_index(drop=True)\n",
    "val_df = whole_df[whole_df.id.isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = SitsDataset(train_df)\n",
    "val_dataset = SitsDataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del whole_df\n",
    "del train_df\n",
    "del val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SitsLightningModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(SitsLightningModel, self).__init__()\n",
    "        self.model = SitsTransformer()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Initialize Macro F1 score for training, validation, and test\n",
    "        self.val_f1 = MulticlassF1Score(num_classes=13, average='macro')\n",
    "        self.test_f1 = MulticlassF1Score(num_classes=13, average='macro')\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(batch, True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Check if any output is NaN\n",
    "        if torch.isnan(outputs).any():\n",
    "            print(\"outputs\")\n",
    "            print(outputs)\n",
    "\n",
    "            print(\"\\ntargets\")\n",
    "            print(targets)\n",
    "\n",
    "            print(\"\\nxs\")\n",
    "            print(inputs[\"x\"])\n",
    "\n",
    "            print(\"\\ndoys\")\n",
    "            print(inputs[\"doy\"])\n",
    "\n",
    "            print(\"\\nmasks\")\n",
    "            print(inputs[\"mask\"])\n",
    "\n",
    "            raise Exception(\"NaN detected in training output\")\n",
    "\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        # Log loss and F1 score\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        f1_score = self.val_f1(preds, targets)\n",
    "\n",
    "        # Log loss and F1 score\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_score, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        f1_score = self.test_f1(preds, targets)\n",
    "\n",
    "        # Log loss and F1 score\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_f1\", f1_score)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=150)\n",
    "\n",
    "# Initialize the model\n",
    "model = SitsLightningModel()\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
