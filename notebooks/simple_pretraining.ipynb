{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "\n",
    "from print_color import print\n",
    "\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.utils.debug import std_of_l2_normalized\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead, SimSiamProjectionHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TRANSFORMER_FROM_SCRATCH\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sits_siam.backbone import TransformerBackbone\n",
    "from sits_siam.head import BertHead, ClassifierHead\n",
    "from sits_siam.utils import SitsDataset\n",
    "from sits_siam.bottleneck import PoolingBottleneck, NDVIWord2VecBottleneck\n",
    "from sits_siam.augment import AddNDVIWeights, RandomChanSwapping, RandomChanRemoval, RandomAddNoise, RandomTempSwapping, RandomTempShift, RandomTempRemoval, AddMissingMask, Normalize, Pipeline, ToPytorchTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed():\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# setup_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_parquet(\"data/california_sits_bert_original.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = [0.0656, 0.0948, 0.1094, 0.1507, 0.2372, 0.2673, 0.2866, 0.2946, 0.2679, 0.1985]\n",
    "iqd = [0.0456, 0.0536, 0.0946, 0.0769, 0.0851, 0.1053, 0.1066, 0.1074, 0.1428, 0.1376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSiamMultiViewTransform(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_views: int = 2,\n",
    "    ):\n",
    "        self.n_views = n_views\n",
    "        self.transform = Pipeline([\n",
    "            # AddNDVIWeights(),\n",
    "            RandomAddNoise(),\n",
    "            RandomTempSwapping(),\n",
    "            RandomTempShift(),\n",
    "            # RandomTempRemoval(),\n",
    "            AddMissingMask(),\n",
    "            Normalize(\n",
    "                a=median,\n",
    "                b=iqd,\n",
    "            ),\n",
    "            ToPytorchTensor()\n",
    "        ])\n",
    "\n",
    "    def __call__(self, sample: np.ndarray):\n",
    "        return [self.transform({k: v.copy() for k, v in sample.items()}) for _ in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_parquet(\"data/california_sits_bert_original.parquet\")\n",
    "\n",
    "train_df = whole_df[whole_df.use_bert.isin([0, 2])].reset_index(drop=True)\n",
    "val_df = whole_df[whole_df.use_bert==1].reset_index(drop=True)\n",
    "\n",
    "train_dataset = SitsDataset(train_df, max_seq_len=45, transform=FastSiamMultiViewTransform())\n",
    "val_dataset = SitsDataset(val_df, max_seq_len=45, transform=FastSiamMultiViewTransform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable scientific notation pytorch, keep 3 numbers after decimal\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(pl.LightningModule):\n",
    "    def __init__(self, max_seq_len=45):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.backbone = TransformerBackbone(max_seq_len=max_seq_len)\n",
    "        self.bottleneck = PoolingBottleneck()\n",
    "        self.projection_head = SimSiamProjectionHead(128, 512, 128)\n",
    "        self.prediction_head = SimSiamPredictionHead(128, 64, 128)\n",
    "\n",
    "        self.criterion = NegativeCosineSimilarity()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input[\"x\"]\n",
    "        doy = input[\"doy\"]\n",
    "        mask = input[\"mask\"]\n",
    "        # weight = input[\"weight\"]\n",
    "\n",
    "        f = self.backbone(x, doy, mask)\n",
    "        f = self.bottleneck(f)\n",
    "        z = self.projection_head(f)\n",
    "        p = self.prediction_head(z)\n",
    "        z = z.detach()\n",
    "        return z, p\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        views = batch\n",
    "        features = [self.forward(view) for view in views]\n",
    "        zs = torch.stack([z for z, _ in features])\n",
    "        ps = torch.stack([p for _, p in features])\n",
    "\n",
    "        loss = 0.0\n",
    "        for i in range(len(views)):\n",
    "            mask = torch.arange(len(views), device=self.device) != i\n",
    "            loss += self.criterion(ps[i], torch.mean(zs[mask], dim=0)) / len(views)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_collapse\", std_of_l2_normalized(ps[0].detach()), sync_dist=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        views = batch\n",
    "        features = [self.forward(view) for view in views]\n",
    "        zs = torch.stack([z for z, _ in features])\n",
    "        ps = torch.stack([p for _, p in features])\n",
    "\n",
    "        loss = 0.0\n",
    "        for i in range(len(views)):\n",
    "            mask = torch.arange(len(views), device=self.device) != i\n",
    "            loss += self.criterion(ps[i], torch.mean(zs[mask], dim=0)) / len(views)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_collapse\", std_of_l2_normalized(ps[0].detach()), sync_dist=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        views = batch\n",
    "        features = [self.forward(view) for view in views]\n",
    "        zs = torch.stack([z for z, _ in features])\n",
    "        ps = torch.stack([p for _, p in features])\n",
    "\n",
    "        loss = 0.0\n",
    "        for i in range(len(views)):\n",
    "            mask = torch.arange(len(views), device=self.device) != i\n",
    "            loss += self.criterion(ps[i], torch.mean(zs[mask], dim=0)) / len(views)\n",
    "\n",
    "        self.log(\"test_loss\", loss, sync_dist=True)\n",
    "        self.log(\"test_collapse\", std_of_l2_normalized(ps[0].detach()), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "        return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=20)\n",
    "model = TransformerClassifier()\n",
    "\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Pare malandro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSiamTestTransform(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_views: int = 1,\n",
    "        a=None,\n",
    "        b=None\n",
    "    ):\n",
    "        self.n_views = n_views\n",
    "        self.transform = [\n",
    "            AddNDVIWeights(),\n",
    "            # RandomAddNoise(),\n",
    "            # RandomTempSwapping(),\n",
    "            # RandomTempShift(),\n",
    "            # RandomTempRemoval(),\n",
    "            AddMissingMask(),\n",
    "            Normalize(\n",
    "                a=a,\n",
    "                b=b,\n",
    "            ),\n",
    "            ToPytorchTensor()\n",
    "        ]\n",
    "\n",
    "    def apply_transform(self, sample):\n",
    "\n",
    "        sample = {k: v.copy() for k, v in sample.items()} # Avoid side effects since augmentations are in place\n",
    "        for t in self.transform:\n",
    "            sample = t(sample)\n",
    "        return sample\n",
    "\n",
    "    def __call__(self, sample: np.ndarray):\n",
    "        return [self.apply_transform(sample) for _ in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = model.backbone\n",
    "bottleneck = model.bottleneck\n",
    "backbone.eval()\n",
    "bottleneck.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = None\n",
    "with torch.inference_mode():\n",
    "    for batch in train_dataloader:\n",
    "        sample = batch[0]\n",
    "\n",
    "        x = sample[\"x\"]\n",
    "        doy = sample[\"doy\"]\n",
    "        mask = sample[\"mask\"]\n",
    "        \n",
    "        f = backbone(x, doy, mask)\n",
    "        f = bottleneck(f)\n",
    "        if all_features is None:\n",
    "            all_features = f\n",
    "        else:\n",
    "            all_features = torch.cat([all_features, f], dim=0)\n",
    "\n",
    "train_df_with_features = train_df[[\"id\", \"label\"]].groupby(\"id\").first().reset_index()\n",
    "train_df_with_features = train_df_with_features.merge(pd.DataFrame(all_features.detach().numpy(), columns=[f\"feature_{i}\" for i in range(all_features.shape[1])]), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2, n_iter=250)\n",
    "tsne.fit(train_df_with_features[[column for column in train_df_with_features.columns if column.startswith(\"feature_\")]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = None\n",
    "with torch.inference_mode():\n",
    "    for batch in val_dataloader:\n",
    "        sample = batch[0]\n",
    "\n",
    "        x = sample[\"x\"]\n",
    "        doy = sample[\"doy\"]\n",
    "        mask = sample[\"mask\"]\n",
    "        \n",
    "        f = backbone(x, doy, mask)\n",
    "        f = bottleneck(f)\n",
    "        if all_features is None:\n",
    "            all_features = f\n",
    "        else:\n",
    "            all_features = torch.cat([all_features, f], dim=0)\n",
    "\n",
    "val_df_with_features = val_df[[\"id\", \"label\"]].groupby(\"id\").first().reset_index()\n",
    "val_df_with_features = val_df_with_features.merge(pd.DataFrame(all_features.detach().numpy(), columns=[f\"feature_{i}\" for i in range(all_features.shape[1])]), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting TSNE of dataframe features in two dimensions\n",
    "\n",
    "X_embedded = tsne.fit_transform(all_features.cpu().detach().numpy())\n",
    "\n",
    "val_df_with_features[\"tsne-2d-one\"] = X_embedded[:, 0]\n",
    "val_df_with_features[\"tsne-2d-two\"] = X_embedded[:, 1]\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    palette=sns.color_palette(\"hsv\", len(val_df_with_features.label.unique())),\n",
    "    data=val_df_with_features[[\"tsne-2d-one\", \"tsne-2d-two\", \"label\"]],\n",
    "    legend=\"full\",\n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_df_with_features[[column for column in train_df_with_features.columns if column.startswith(\"feature_\")]], train_df_with_features.label)\n",
    "y_pred = knn.predict(val_df_with_features[[column for column in train_df_with_features.columns if column.startswith(\"feature_\")]])\n",
    "\n",
    "f1 = f1_score(val_df_with_features.label, y_pred, average=\"weighted\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
